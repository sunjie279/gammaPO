llama-3-8b-it-gmsimpo-beta10-gm0.4-tau10-lr1e-6:
  completions_kwargs:
    batch_size: 900
    do_sample: true
    max_new_tokens: 4096
    model_kwargs:
      torch_dtype: bfloat16
    model_name: outputs/llama-3-8b-it-gmsimpo-beta10-gm0.4-tau10-lr1e-6
    stop_token_ids:
    - 128001
    - 128009
    temperature: 0.9
    top_p: 1.0
  fn_completions: vllm_local_completions
  pretty_name: llama-3-8b-it-gmsimpo-beta10-gm0.4-tau10-lr1e-6
  prompt_template: eval/alpacaeval2/template/llama3.txt
